## Co-speech Generation
- [ICCV 2023] Continual Learning for Personalized Co-speech Gesture Generation.[[paper]](https://openaccess.thecvf.com/content/ICCV2023/html/Ahuja_Continual_Learning_for_Personalized_Co-speech_Gesture_Generation_ICCV_2023_paper.html)     
*Chaitanya Ahuja, Pratik Joshi, Ryo Ishii, Louis-Philippe Morency*
- [ICCV 2023] LivelySpeaker: Towards Semantic-Aware Co-Speech Gesture Generation.[[paper]](https://openaccess.thecvf.com/content/ICCV2023/html/Zhi_LivelySpeaker_Towards_Semantic-Aware_Co-Speech_Gesture_Generation_ICCV_2023_paper.html)     
*Yihao Zhi, Xiaodong Cun, Xuelin Chen, Xi Shen, Wen Guo, Shaoli Huang, Shenghua Gao*
- [CVPR 2023]  QPGesture: Quantization-Based and Phase-Guided Motion Matching for Natural Speech-Driven Gesture Generation.[[paper]](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_QPGesture_Quantization-Based_and_Phase-Guided_Motion_Matching_for_Natural_Speech-Driven_Gesture_CVPR_2023_paper.html)     
*SiCheng Yang, Zhiyong Wu, Minglei Li, Zhensong Zhang, Lei Hao, Weihong Bao, Haolin Zhuang*
- [CVPR 2023]  Taming Diffusion Models for Audio-Driven Co-Speech Gesture Generation.[[paper]](https://openaccess.thecvf.com/content/CVPR2023/html/Zhu_Taming_Diffusion_Models_for_Audio-Driven_Co-Speech_Gesture_Generation_CVPR_2023_paper.html)     
*Lingting Zhu, Xian Liu, Xuanyu Liu, Rui Qian, Ziwei Liu, Lequan Yu*
- [CVPR 2023]  Diverse 3D Hand Gesture Prediction from Body Dynamics by Bilateral Hand Disentanglement.[[paper]](https://openaccess.thecvf.com/content/CVPR2023/html/Qi_Diverse_3D_Hand_Gesture_Prediction_From_Body_Dynamics_by_Bilateral_CVPR_2023_paper.html)     
*Xingqun Qi, Chen Liu, Muyi Sun, Lincheng Li, Changjie Fan, Xin Yu*
- [CVPR 2023]  Co-speech Gesture Synthesis by Reinforcement Learning with Contrastive Pre-trained Rewards.[[paper]](https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Co-Speech_Gesture_Synthesis_by_Reinforcement_Learning_With_Contrastive_Pre-Trained_Rewards_CVPR_2023_paper.html)     
*Mingyang Sun, Mengchen Zhao, Yaqing Hou, Minglei Li, Huang Xu, Songcen Xu, Jianye HAO*
- [ECCV 2022] BEAT: A Large-Scale Semantic and Emotional Multi-Modal Dataset for Conversational Gestures Synthesis.[[paper]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/296_ECCV_2022_paper.php)      
  *Haiyang Liu, Zihao Zhu, Naoya Iwamoto, Yichen Peng, Zhengqing Li, You Zhou, Elif Bozkurt, Bo Zheng*
- [ECCV 2022] Audio-Driven Stylized Gesture Generation with Flow-Based Model.[[paper]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/3948_ECCV_2022_paper.php)       
  *Sheng Ye, Yu-Hui Wen, Yanan Sun, Ying He, Ziyang Zhang, Yaoyuan Wang, Weihua He, Yong-Jin Liu*
- [CVPR 2022] Audio-Driven Neural Gesture Reenactment With Video Motion Graphs.[[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Audio-Driven_Neural_Gesture_Reenactment_With_Video_Motion_Graphs_CVPR_2022_paper.html)    
  *Yang Zhou; Jimei Yang; Dingzeyu Li; Jun Saito; Deepali Aneja; Evangelos Kalogerakis*
- [CVPR 2022] Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation.[[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Hierarchical_Cross-Modal_Association_for_Co-Speech_Gesture_Generation_CVPR_2022_paper.html)   
  *Xian Liu; Qianyi Wu; Hang Zhou; Yinghao Xu; Rui Qian; Xinyi Lin; Xiaowei Zhou; Wayne Wu; Bo Dai; Bolei Zhou*
- [CVPR 2022] SEEG: Semantic Energized Co-Speech Gesture Generation.[[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_SEEG_Semantic_Energized_Co-Speech_Gesture_Generation_CVPR_2022_paper.html)   
  *Yuanzhi Liang; Qianyu Feng; Linchao Zhu; Li Hu; Pan Pan; Yi Yang*
- [CVPR 2022] Low-Resource Adaptation for Personalized Co-Speech Gesture Generation.[[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Ahuja_Low-Resource_Adaptation_for_Personalized_Co-Speech_Gesture_Generation_CVPR_2022_paper.html)       
  *Chaitanya Ahuja; Dong Won Lee; Louis-Philippe Morency*
- [ICCV 2021] Speech Drives Templates: Co-Speech Gesture Synthesis With Learned Templates.[[paper]](https://openaccess.thecvf.com/content/ICCV2021/html/Qian_Speech_Drives_Templates_Co-Speech_Gesture_Synthesis_With_Learned_Templates_ICCV_2021_paper.html)     
   *Shenhan Qian; Zhi Tu; Yihao Zhi; Wen Liu; Shenghua Gao*
- [ICCV 2021] Audio2Gestures: Generating Diverse Gestures From Speech Audio With Conditional Variational Autoencoders.[[paper]](https://openaccess.thecvf.com/content/ICCV2021/html/Li_Audio2Gestures_Generating_Diverse_Gestures_From_Speech_Audio_With_Conditional_Variational_ICCV_2021_paper.html)    
   *Jing Li; Di Kang; Wenjie Pei; Xuefei Zhe; Ying Zhang; Zhenyu He; Linchao Bao*
- [ACM MM 2021] Speech2AffectiveGestures: Synthesizing Co-Speech Gestures with Generative Adversarial Affective Expression Learning.[[paper]](https://arxiv.org/abs/2108.00262)    
  *Uttaran Bhattacharya, Elizabeth Childs, Nicholas S Rewkowski, Dinesh Manocha*
- [CVPR 2021] iMiGUE: An Identity-Free Video Dataset for Micro-Gesture Understanding and Emotion Analysis.[[paper]](https://openaccess.thecvf.com/content/CVPR2021/html/Liu_iMiGUE_An_Identity-Free_Video_Dataset_for_Micro-Gesture_Understanding_and_Emotion_CVPR_2021_paper.html)    
  *Xin Liu, Henglin Shi, Haoyu Chen, Zitong Yu, Xiaobai Li, Guoying Zhao*
- [CVPR 2021] Body2Hands: Learning To Infer 3D Hands From Conversational Gesture Body Dynamics. [[paper]](https://arxiv.org/abs/2007.12287)  
  *Evonne Ng, Shiry Ginosar, Trevor Darrell, Hanbyul Joo*
- [ECCV 2020] Style Transfer for Co-Speech Gesture Animation: A Multi-Speaker Conditional-Mixture Approach. [[paper]](https://arxiv.org/pdf/2007.12553.pdf)    
  *Chaitanya Ahuja, Dong Won Lee, Yukiko I. Nakano, and Louis-Philippe Morency*
- [ICCV 2019] Talking With Hands 16.2M: A Large-Scale Dataset of Synchronized Body-Finger Motion and Audio for Conversational Motion Analysis and Synthesis. [[paper]]( http://openaccess.thecvf.com/content_ICCV_2019/papers/Lee_Talking_With_Hands_16.2M_A_Large-Scale_Dataset_of_Synchronized_Body-Finger_ICCV_2019_paper.pdf )   
   *Gilwoo Lee, Zhiwei Deng, Shugao Ma, Takaaki Shiratori, Siddhartha S. Srinivasa, Yaser Sheikh*
- [CVPR 2019] Learning Individual Styles of Conversational Gesture. [[paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Ginosar_Learning_Individual_Styles_of_Conversational_Gesture_CVPR_2019_paper.pdf)  
   *Shiry Ginosar, Amir Bar, Gefen Kohavi, Caroline Chan, Andrew Owens, Jitendra Malik*